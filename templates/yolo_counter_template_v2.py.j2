"""
{{ class_name }} - Enhanced YOLO-based {{ object_class }} counter
Generated automatically for {{ logic_type }} detection using landmark-based approach
"""

import cv2
import numpy as np
from yolo_tracker import YOLOTracker

class {{ class_name }}:
    def __init__(self):
        # YOLO Configuration
        self.object_class = "{{ object_class }}"
        self.detection_type = "yolo"
        self.logic_type = "{{ logic_type }}"
        
        # Detection parameters
        self.threshold = {{ threshold }}
        self.confidence_threshold = {{ confidence_threshold }}
        self.stable_frames = {{ stable_frames }}
        
        # Counter state
        self.count = 0
        self.state = "start"  # start, up, down, moving
        self.stable_count = 0
        
        # Landmark tracking (using bounding box as landmarks)
        self.start_position = None
        self.current_position = None
        self.up_threshold = None
        self.down_threshold = None
        
        # Movement history for pattern detection and adaptive thresholds
        self.position_history = []
        self.calibration_frames = 30  # Reduced for faster calibration
        self.calibrated = False
        
        # Adaptive threshold calculation
        self.position_variance = 0
        self.movement_range = 0
        self.adaptive_multiplier = 1.0
        
        # Frame scaling tracking
        self.original_frame_size = None
        self.display_scale = 1.0
        
        # YOLO tracker
        self.tracker = YOLOTracker(
            object_class=self.object_class,
            confidence_threshold=self.confidence_threshold
        )
        
        # Debug info
        self.debug_info = {
            'detected': False,
            'confidence': 0.0,
            'state': self.state,
            'is_up': False,
            'is_down': False,
            'is_at_start': False,
            'position_y': 0,
            'start_y': 0,
            'up_threshold': 0,
            'down_threshold': 0,
            'movement_range': 0,
            'adaptive_multiplier': 1.0
        }
    
    def update(self, frame):
        """
        Update counter with new frame using landmark-based detection.
        
        Args:
            frame: OpenCV frame (numpy array)
            
        Returns:
            int: Current count
        """
        # Store original frame size for proper scaling
        if self.original_frame_size is None:
            self.original_frame_size = (frame.shape[1], frame.shape[0])  # width, height
        
        # Detect objects in frame
        detections = self.tracker.detect_objects(frame)
        best_detection = self.tracker.get_best_detection(detections)
        
        if best_detection:
            self.debug_info['detected'] = True
            self.debug_info['confidence'] = best_detection['confidence']
            
            # Get position from bounding box center (in original coordinates)
            bbox = best_detection['bbox']
            center_x = (bbox[0] + bbox[2]) / 2
            center_y = (bbox[1] + bbox[3]) / 2
            self.current_position = (center_x, center_y)
            
            # Calibration phase
            if not self.calibrated:
                self._calibrate_position_adaptive(center_y)
                return self.count
            
            # Update position tracking
            self.position_history.append(center_y)
            if len(self.position_history) > 20:  # Keep last 20 positions for analysis
                self.position_history.pop(0)
            
            # Apply detection logic
            {% if logic_type == "bounce_detection" %}
            self._detect_bounce(center_y)
            {% elif logic_type == "jump_detection" %}
            self._detect_jump(center_y)
            {% elif logic_type == "movement_detection" %}
            self._detect_movement(center_y)
            {% else %}
            self._detect_vertical_movement(center_y)
            {% endif %}
            
            # Update debug info
            self._update_debug_info(center_y)
            
        else:
            self.debug_info['detected'] = False
            self.debug_info['confidence'] = 0.0
        
        self.debug_info['state'] = self.state
        return self.count
    
    def _calibrate_position_adaptive(self, center_y):
        """Enhanced calibration with adaptive threshold calculation."""
        self.position_history.append(center_y)
        
        if len(self.position_history) >= self.calibration_frames:
            # Calculate start position as median for stability
            sorted_positions = sorted(self.position_history)
            self.start_position = sorted_positions[len(sorted_positions) // 2]
            
            # Calculate movement variance and range for adaptive thresholds
            positions_array = np.array(self.position_history)
            self.position_variance = np.std(positions_array)
            self.movement_range = np.max(positions_array) - np.min(positions_array)
            
            # Adaptive multiplier based on object characteristics
            {% if logic_type == "bounce_detection" %}
            # Bouncing objects need larger thresholds
            base_multiplier = 1.2
            variance_factor = max(1.0, self.position_variance / 10)
            {% elif logic_type == "jump_detection" %}
            # Animals jumping - asymmetric thresholds
            base_multiplier = 1.0
            variance_factor = max(0.8, self.position_variance / 15)
            {% else %}
            # General movement - moderate thresholds
            base_multiplier = 0.8
            variance_factor = max(0.6, self.position_variance / 20)
            {% endif %}
            
            self.adaptive_multiplier = base_multiplier * variance_factor
            
            # Calculate adaptive thresholds
            {% if logic_type == "bounce_detection" %}
            # Symmetric thresholds for bouncing
            threshold_adjusted = max(self.threshold, self.movement_range * 0.3) * self.adaptive_multiplier
            self.up_threshold = self.start_position - threshold_adjusted
            self.down_threshold = self.start_position + threshold_adjusted
            {% elif logic_type == "jump_detection" %}
            # Asymmetric thresholds - up movement is primary
            up_threshold_adjusted = max(self.threshold * 0.8, self.movement_range * 0.4) * self.adaptive_multiplier
            down_threshold_adjusted = max(self.threshold * 0.3, self.movement_range * 0.2) * self.adaptive_multiplier
            self.up_threshold = self.start_position - up_threshold_adjusted
            self.down_threshold = self.start_position + down_threshold_adjusted
            {% else %}
            # Balanced thresholds for general movement
            threshold_adjusted = max(self.threshold * 0.6, self.movement_range * 0.25) * self.adaptive_multiplier
            self.up_threshold = self.start_position - threshold_adjusted
            self.down_threshold = self.start_position + threshold_adjusted
            {% endif %}
            
            self.calibrated = True
            print(f"🎯 {{ class_name }} adaptively calibrated:")
            print(f"   Start position: {self.start_position:.1f}")
            print(f"   Movement range: {self.movement_range:.1f}")
            print(f"   Position variance: {self.position_variance:.1f}")
            print(f"   Adaptive multiplier: {self.adaptive_multiplier:.2f}")
            print(f"   Up threshold: {self.up_threshold:.1f}")
            print(f"   Down threshold: {self.down_threshold:.1f}")
    
    def _detect_bounce(self, center_y):
        """Detect bouncing movement pattern with adaptive sensitivity."""
        if self.state == "start":
            if center_y > self.down_threshold:
                self.state = "down"
                self.stable_count = 0
        
        elif self.state == "down":
            if center_y < self.up_threshold:
                self.stable_count += 1
                if self.stable_count >= self.stable_frames:
                    self._increment_count()
                    self.state = "start"
                    self.stable_count = 0
            elif center_y < self.down_threshold:
                self.stable_count = 0
    
    def _detect_jump(self, center_y):
        """Detect jumping movement pattern optimized for animals."""
        if self.state == "start":
            if center_y < self.up_threshold:
                self.state = "up"
                self.stable_count = 0
        
        elif self.state == "up":
            # More lenient return condition for animals
            return_threshold = self.start_position + (self.start_position - self.up_threshold) * 0.3
            if center_y > return_threshold:
                self.stable_count += 1
                if self.stable_count >= self.stable_frames:
                    self._increment_count()
                    self.state = "start"
                    self.stable_count = 0
            elif center_y > self.up_threshold:
                self.stable_count = 0
    
    def _detect_movement(self, center_y):
        """Detect general movement pattern with improved sensitivity."""
        if self.state == "start":
            if center_y < self.up_threshold or center_y > self.down_threshold:
                self.state = "moving"
                self.stable_count = 0
        
        elif self.state == "moving":
            # Dynamic return zone based on movement range
            return_zone = max(self.threshold * 0.3, self.movement_range * 0.15)
            if abs(center_y - self.start_position) < return_zone:
                self.stable_count += 1
                if self.stable_count >= self.stable_frames:
                    self._increment_count()
                    self.state = "start"
                    self.stable_count = 0
            else:
                self.stable_count = 0
    
    def _detect_vertical_movement(self, center_y):
        """Default vertical movement detection with adaptive thresholds."""
        if self.state == "start":
            if center_y < self.up_threshold:
                self.state = "up"
            elif center_y > self.down_threshold:
                self.state = "down"
        
        elif self.state == "up":
            if center_y > self.start_position:
                self._increment_count()
                self.state = "start"
        
        elif self.state == "down":
            if center_y < self.start_position:
                self._increment_count()
                self.state = "start"
    
    def _update_debug_info(self, center_y):
        """Update debug information."""
        self.debug_info.update({
            'position_y': center_y,
            'start_y': self.start_position or 0,
            'up_threshold': self.up_threshold or 0,
            'down_threshold': self.down_threshold or 0,
            'is_up': center_y < (self.up_threshold or float('inf')),
            'is_down': center_y > (self.down_threshold or float('-inf')),
            'is_at_start': abs(center_y - (self.start_position or center_y)) < (self.threshold * 0.3) if self.start_position else False,
            'movement_range': self.movement_range,
            'adaptive_multiplier': self.adaptive_multiplier
        })
    
    def _increment_count(self):
        """Increment the counter."""
        self.count += 1
        print(f"🎯 {{ class_name }}: {self.count} ({{ object_class }})")
    
    def reset(self):
        """Reset the counter."""
        self.count = 0
        self.state = "start"
        self.stable_count = 0
        self.start_position = None
        self.current_position = None
        self.position_history.clear()
        self.calibrated = False
        self.position_variance = 0
        self.movement_range = 0
        self.adaptive_multiplier = 1.0
        self.original_frame_size = None
        self.display_scale = 1.0
        self.tracker.movement_history.clear()
        self.tracker.previous_center = None
    
    def draw_debug_info(self, frame, detection=None):
        """
        Draw debug information on frame with proper scaling correction.
        Uses proper aspect ratio scaling for all video formats including vertical videos.
        
        Args:
            frame: OpenCV frame to draw on
            detection: Current detection (optional)
        """
        # Get original dimensions
        original_height, original_width = frame.shape[:2]
        
        # Store original frame size for scaling calculations
        if self.original_frame_size is None:
            self.original_frame_size = (original_width, original_height)
        
        # Calculate proper scaling maintaining aspect ratio
        target_width = 480
        
        # Calculate scale factor and new dimensions
        scale = original_width / target_width
        fixed_height = int(original_height / scale)  # This maintains aspect ratio
        
        # For very tall videos (like 540x1080), limit height to reasonable size
        max_height = 800
        if fixed_height > max_height:
            # Recalculate scale based on height constraint
            scale = original_height / max_height
            target_width = int(original_width / scale)
            fixed_height = max_height
        
        # Create display frame with proper scaling
        display_frame = cv2.resize(frame, (target_width, fixed_height))
        self.display_scale = 1.0 / scale  # Scale factor for coordinates
        
        # Scale detection coordinates for display if provided
        scaled_detection = None
        if detection:
            bbox = detection['bbox']
            scaled_detection = {
                'bbox': (
                    int(bbox[0] * self.display_scale),
                    int(bbox[1] * self.display_scale),
                    int(bbox[2] * self.display_scale),
                    int(bbox[3] * self.display_scale)
                ),
                'center': (
                    int(detection['center'][0] * self.display_scale),
                    int(detection['center'][1] * self.display_scale)
                ),
                'confidence': detection['confidence']
            }
        
        # Draw detection if available
        if scaled_detection:
            display_frame = self.tracker.draw_detection(display_frame, scaled_detection)
        
        # Draw thresholds and position indicators - ENSURE THEY ARE VISIBLE
        if self.calibrated and self.start_position is not None:
            # Scale threshold positions to display coordinates
            start_y = int(self.start_position * self.display_scale)
            up_y = int(self.up_threshold * self.display_scale) if self.up_threshold is not None else start_y - 30
            down_y = int(self.down_threshold * self.display_scale) if self.down_threshold is not None else start_y + 30
            
            # Get display frame dimensions
            frame_height = display_frame.shape[0]
            frame_width = display_frame.shape[1]
            
            # Ensure lines are within frame bounds
            start_y = max(5, min(frame_height - 5, start_y))
            up_y = max(5, min(frame_height - 5, up_y))
            down_y = max(5, min(frame_height - 5, down_y))
            
            # Draw threshold lines with thick lines for visibility
            line_thickness = 3
            cv2.line(display_frame, (0, start_y), (frame_width, start_y), (0, 255, 255), line_thickness)  # Yellow start line
            cv2.line(display_frame, (0, up_y), (frame_width, up_y), (0, 255, 0), line_thickness)        # Green up line  
            cv2.line(display_frame, (0, down_y), (frame_width, down_y), (255, 0, 0), line_thickness)    # Blue down line
            
            # Add threshold zone visualization for better visibility
            if up_y < down_y:
                # Create overlay for transparent zones
                overlay = display_frame.copy()
                alpha = 0.15  # Transparency level
                
                # Draw zones with different colors
                if up_y < start_y:
                    cv2.rectangle(overlay, (0, up_y), (frame_width, start_y), (0, 255, 0), -1)  # Up zone (green)
                if start_y < down_y:
                    cv2.rectangle(overlay, (0, start_y), (frame_width, down_y), (255, 255, 0), -1)  # Start zone (yellow)
                if down_y < frame_height:
                    cv2.rectangle(overlay, (0, down_y), (frame_width, frame_height), (255, 0, 0), -1)  # Down zone (blue)
                
                # Blend overlay with original frame
                cv2.addWeighted(display_frame, 1 - alpha, overlay, alpha, 0, display_frame)
            
            # Add labels with solid background for better readability
            label_font = cv2.FONT_HERSHEY_SIMPLEX
            label_scale = 0.5
            label_thickness = 2
            label_bg_color = (0, 0, 0)
            
            # START label
            start_text = "START"
            (text_width, text_height), _ = cv2.getTextSize(start_text, label_font, label_scale, label_thickness)
            cv2.rectangle(display_frame, (5, start_y - text_height - 5), (5 + text_width + 10, start_y - 2), label_bg_color, -1)
            cv2.putText(display_frame, start_text, (10, start_y - 5), label_font, label_scale, (0, 255, 255), label_thickness)
            
            # UP label
            up_text = "UP"
            (text_width, text_height), _ = cv2.getTextSize(up_text, label_font, label_scale, label_thickness)
            cv2.rectangle(display_frame, (5, up_y - text_height - 5), (5 + text_width + 10, up_y - 2), label_bg_color, -1)
            cv2.putText(display_frame, up_text, (10, up_y - 5), label_font, label_scale, (0, 255, 0), label_thickness)
            
            # DOWN label
            down_text = "DOWN"
            (text_width, text_height), _ = cv2.getTextSize(down_text, label_font, label_scale, label_thickness)
            cv2.rectangle(display_frame, (5, down_y + 5), (5 + text_width + 10, down_y + text_height + 8), label_bg_color, -1)
            cv2.putText(display_frame, down_text, (10, down_y + text_height + 5), label_font, label_scale, (255, 0, 0), label_thickness)
            
            # Debug: Print threshold values to console for verification
            print(f"🔍 Threshold Lines: START={start_y}, UP={up_y}, DOWN={down_y} (Display: {frame_width}x{frame_height})")
        
        # Draw counter info with better formatting
        info_text = [
            f"{{ class_name }}: {self.count}",
            f"Object: {{ object_class }}",
            f"State: {self.state}",
            f"Detected: {self.debug_info['detected']}",
            f"Confidence: {self.debug_info['confidence']:.2f}",
            f"Calibrated: {self.calibrated}"
        ]
        
        # Add position info if calibrated
        if self.calibrated:
            info_text.extend([
                f"Position Y: {self.debug_info['position_y']:.1f}",
                f"Start Pos: {self.start_position:.1f}",
                f"Up Threshold: {self.up_threshold:.1f}" if self.up_threshold else "Up Threshold: None",
                f"Down Threshold: {self.down_threshold:.1f}" if self.down_threshold else "Down Threshold: None",
                f"Movement Range: {self.movement_range:.1f}",
                f"Adaptive Mult: {self.adaptive_multiplier:.2f}",
                f"At Start: {self.debug_info['is_at_start']}",
                f"Is Up: {self.debug_info['is_up']}",
                f"Is Down: {self.debug_info['is_down']}"
            ])
        
        # Add scaling info - show actual calculated dimensions
        aspect_ratio = original_width / original_height
        info_text.extend([
            f"Original: {original_width}x{original_height}",
            f"Display: {target_width}x{fixed_height}",
            f"Aspect Ratio: {aspect_ratio:.2f}",
            f"Scale Factor: {scale:.2f}",
            f"Display Scale: {self.display_scale:.2f}"
        ])
        
        # Draw info panel with background
        panel_width = 320
        panel_height = len(info_text) * 20 + 20
        
        # Ensure panel doesn't go off screen
        panel_x = 10
        panel_y = 10
        if panel_x + panel_width > display_frame.shape[1]:
            panel_x = display_frame.shape[1] - panel_width - 10
        if panel_y + panel_height > display_frame.shape[0]:
            panel_y = display_frame.shape[0] - panel_height - 10
        
        # Draw panel background
        cv2.rectangle(display_frame, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height), (0, 0, 0), -1)
        cv2.rectangle(display_frame, (panel_x, panel_y), (panel_x + panel_width, panel_y + panel_height), (255, 255, 255), 2)
        
        # Draw info text
        y_offset = panel_y + 20
        for i, text in enumerate(info_text):
            cv2.putText(display_frame, text, (panel_x + 10, y_offset + i * 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return display_frame
    
    def get_debug_info(self):
        """Get debug information for web interface."""
        return {
            'count': self.count,
            'state': self.state,
            'detected': self.debug_info['detected'],
            'confidence': self.debug_info['confidence'],
            'object_class': self.object_class,
            'logic_type': self.logic_type,
            'calibrated': self.calibrated,
            'position_y': self.debug_info.get('position_y', 0),
            'start_y': self.debug_info.get('start_y', 0),
            'is_up': self.debug_info.get('is_up', False),
            'is_down': self.debug_info.get('is_down', False),
            'is_at_start': self.debug_info.get('is_at_start', False),
            'movement_range': self.debug_info.get('movement_range', 0),
            'adaptive_multiplier': self.debug_info.get('adaptive_multiplier', 1.0),
            'display_scale': self.display_scale
        } 